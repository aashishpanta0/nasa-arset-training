{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f42505d",
   "metadata": {},
   "source": [
    "\n",
    "# ETCCDI Multi-Year Mean + Time-Series Stats + Linear Trend\n",
    "\n",
    "**How to use:** Edit only the **Parameters** cell below, then run all cells (Kernel → Restart & Run All).\n",
    "This notebook:\n",
    "1) Loads an ETCCDI NetCDF\n",
    "2) Computes the **multi-year mean** and plots a **map** + **spatial histogram** + **spatial stats**\n",
    "3) Computes **annual regional values** (area-weighted mean) and plots a **time series** + **histogram across years**\n",
    "4) Fits a **linear trend** to the annual values and plots it, with slope and R² \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 — List available NetCDF files \n",
    "import os, glob\n",
    "\n",
    "# Directory containing your ETCCDI NetCDF outputs\n",
    "DATA_DIR = \"/home/jovyan/shared/NEX-GDDP-CMIP6/ETCCDI/\"  # or user-calculated indices in ./etccdi_out/\"\n",
    "\n",
    "# Gather *.nc files\n",
    "NC_FILES = sorted([os.path.basename(p) for p in glob.glob(os.path.join(DATA_DIR, \"*.nc\"))])\n",
    "\n",
    "print(f\"Found {len(NC_FILES)} .nc files in {DATA_DIR}\")\n",
    "for i, name in enumerate(NC_FILES, 1):\n",
    "    print(f\"{i:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 — Parameters (EDIT by uncommenting and setting values; no defaults)\n",
    "#\n",
    "# Required — pick one file from the list printed in Step 1:\n",
    "FILE_NAME = \"ETCCDI_pr_GISS-E2-1-G_historical_annual_1985-2014_Rx5day.nc\"\n",
    "#\n",
    "\n",
    "FILE_PATH = DATA_DIR + FILE_NAME\n",
    "\n",
    "REGION_METHOD = \"country\"           # or \"bbox\"\n",
    "COUNTRY_NAME = \"Thailand\"\n",
    "\n",
    "BBOX = (100.0, 105.0, 10.0, 15.0)   # (minimum longitude, maximum longitude, minimum latitude, maximum latitude)\n",
    "SHAPEFILE_PATH = \"./shapefile\"\n",
    "BORDERS = True\n",
    "CMAP = \"viridis\"\n",
    "\n",
    "# --- Outputs ---\n",
    "SAVE_OUTPUTS = True                # True to write figures/tables\n",
    "OUT_DIR = \"./outputs\"               # where to save outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "# === Helpers (imports and functions) =========================================\n",
    "import os, glob, math, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional vectorized shapely helper (non-fatal if missing)\n",
    "try:\n",
    "    from shapely import vectorized as shp_vec\n",
    "except Exception:\n",
    "    shp_vec = None\n",
    "\n",
    "# Geopandas and shapely ops for boundaries/masks\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    from shapely.ops import unary_union\n",
    "except Exception as e:\n",
    "    gpd = None\n",
    "    unary_union = None\n",
    "\n",
    "def _standardize_latlon(da: xr.DataArray) -> xr.DataArray:\n",
    "    # Rename common coordinate names to lat/lon\n",
    "    ren = {}\n",
    "    for cand, std in ((\"latitude\",\"lat\"), (\"Latitude\",\"lat\"), (\"y\",\"lat\"),\n",
    "                      (\"longitude\",\"lon\"), (\"Longitude\",\"lon\"), (\"x\",\"lon\")):\n",
    "        if cand in da.coords and std not in da.coords:\n",
    "            ren[cand] = std\n",
    "    if ren:\n",
    "        da = da.rename(ren)\n",
    "    if (\"lat\" not in da.coords) or (\"lon\" not in da.coords):\n",
    "        raise ValueError(\"Data must have 'lat' and 'lon' coordinates.\")\n",
    "    return da\n",
    "\n",
    "def ensure_lon_neg180_180(da: xr.DataArray) -> xr.DataArray:\n",
    "    if \"lon\" not in da.dims:\n",
    "        return da\n",
    "    lon = da[\"lon\"].values\n",
    "    if np.nanmax(lon) > 180.0:\n",
    "        lon_new = ((lon + 180.0) % 360.0) - 180.0\n",
    "        da = da.assign_coords(lon=lon_new).sortby(\"lon\")\n",
    "    return da\n",
    "\n",
    "def load_dataarray(nc_path: str) -> xr.DataArray:\n",
    "    if not os.path.exists(nc_path):\n",
    "        raise FileNotFoundError(f\"NetCDF not found: {nc_path}\")\n",
    "    ds = xr.open_dataset(nc_path)\n",
    "    data_vars = list(ds.data_vars)\n",
    "    if not data_vars:\n",
    "        raise ValueError(f\"No data variables found in {nc_path}\")\n",
    "    # pick variable with lat/lon dims if ambiguous\n",
    "    var = data_vars[0]\n",
    "    for v in data_vars:\n",
    "        if set(ds[v].dims) >= {\"lat\",\"lon\"}:\n",
    "            var = v; break\n",
    "    da = ds[var]\n",
    "    da.name = var\n",
    "    return _standardize_latlon(da)\n",
    "\n",
    "def _resolve_shp(shapefile_path: str) -> str:\n",
    "    if not shapefile_path:\n",
    "        return None\n",
    "    if shapefile_path.lower().endswith(\".shp\") and os.path.exists(shapefile_path):\n",
    "        return shapefile_path\n",
    "    if os.path.isdir(shapefile_path):\n",
    "        cands = sorted(glob.glob(os.path.join(shapefile_path, \"*admin_0_countries*.shp\")))\n",
    "        return cands[0] if cands else None\n",
    "    return shapefile_path if os.path.exists(shapefile_path) else None\n",
    "\n",
    "def load_country_polygon(country: str, shapefile_path: str):\n",
    "    \"\"\"\n",
    "    Read Natural Earth admin_0 countries and union the polygon(s) for `country`.\n",
    "    Prefers NAME, else ADMIN; case-insensitive exact match, then contains.\n",
    "    Accepts a folder (auto-finds the .shp) or a .shp path.\n",
    "    \"\"\"\n",
    "    if not country:\n",
    "        return None\n",
    "    if gpd is None or unary_union is None:\n",
    "        return None\n",
    "\n",
    "    shp = _resolve_shp(shapefile_path)\n",
    "    if not shp:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        gdf = gpd.read_file(shp)\n",
    "    except Exception:\n",
    "        try:\n",
    "            gdf = gpd.read_file(shp, engine=\"pyogrio\")\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # Ensure WGS84\n",
    "    try:\n",
    "        if gdf.crs is not None and gdf.crs.to_epsg() != 4326:\n",
    "            gdf = gdf.to_crs(4326)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    name_col = \"NAME\" if \"NAME\" in gdf.columns else (\"ADMIN\" if \"ADMIN\" in gdf.columns else None)\n",
    "    if name_col is None:\n",
    "        return None\n",
    "\n",
    "    vals_l = gdf[name_col].astype(str).str.lower().str.strip()\n",
    "    target = str(country).lower().strip()\n",
    "\n",
    "    sel = gdf[vals_l == target]\n",
    "    if len(sel) == 0:\n",
    "        sel = gdf[vals_l.str.contains(target, na=False)]\n",
    "    if len(sel) == 0:\n",
    "        return None\n",
    "\n",
    "    return unary_union(sel.geometry.values)\n",
    "\n",
    "def mask_da_by_polygon(da: xr.DataArray, polygon):\n",
    "    if polygon is None:\n",
    "        return da\n",
    "    lons = da[\"lon\"].values\n",
    "    lats = da[\"lat\"].values\n",
    "    lon2d, lat2d = np.meshgrid(lons, lats)\n",
    "    # Fast path if available\n",
    "    try:\n",
    "        if shp_vec is not None and hasattr(shp_vec, \"contains\"):\n",
    "            geom = polygon.buffer(0)\n",
    "            mask = shp_vec.contains(geom, lon2d, lat2d)\n",
    "            return da.where(mask)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback: bbox + prepared geometry per point\n",
    "    try:\n",
    "        from shapely import prepared as shapely_prepared\n",
    "        from shapely.geometry import Point\n",
    "        minx, miny, maxx, maxy = polygon.bounds\n",
    "        bbox_mask = (lon2d >= minx) & (lon2d <= maxx) & (lat2d <= maxy) & (lat2d >= miny)\n",
    "        mask = np.zeros_like(lon2d, dtype=bool)\n",
    "        if bbox_mask.any():\n",
    "            prep = shapely_prepared.prep(polygon)\n",
    "            for (i, j) in np.argwhere(bbox_mask):\n",
    "                if prep.contains(Point(float(lon2d[i, j]), float(lat2d[i, j]))):\n",
    "                    mask[i, j] = True\n",
    "        return da.where(mask)\n",
    "    except Exception:\n",
    "        return da\n",
    "\n",
    "def mask_da_by_bbox(da: xr.DataArray, bbox):\n",
    "    minlon, minlat, maxlon, maxlat = bbox\n",
    "    lon2d, lat2d = np.meshgrid(da[\"lon\"].values, da[\"lat\"].values)\n",
    "    mask = (lon2d >= minlon) & (lon2d <= maxlon) & (lat2d >= minlat) & (lat2d <= maxlat)\n",
    "    return da.where(mask)\n",
    "\n",
    "def plot_map(da_masked: xr.DataArray, title: str, xlim=None, ylim=None, boundary_gdf=None, cmap=None, lw_boundary=0.8, boundary_color='k', zorder_boundary=10):\n",
    "    X, Y = np.meshgrid(da_masked[\"lon\"].values, da_masked[\"lat\"].values)\n",
    "    plt.figure(figsize=(9,4.5))\n",
    "    m = plt.pcolormesh(X, Y, da_masked.values, shading='auto', cmap=(cmap or \"viridis\"))\n",
    "    cb = plt.colorbar(m)\n",
    "    units = da_masked.attrs.get(\"units\",\"\")\n",
    "    if units:\n",
    "        cb.set_label(units)\n",
    "    # overlay boundaries if provided\n",
    "    if boundary_gdf is not None:\n",
    "        ax = plt.gca()\n",
    "        try:\n",
    "            boundary_gdf.boundary.plot(ax=ax, linewidth=0.5, color='k')\n",
    "        except Exception:\n",
    "            pass\n",
    "    plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\"); plt.title(title)\n",
    "    if xlim is not None: plt.xlim(xlim)\n",
    "    if ylim is not None: plt.ylim(ylim)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "def plot_histogram(da_masked: xr.DataArray, title: str):\n",
    "    flat = da_masked.values[np.isfinite(da_masked.values)]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(flat, bins=40)\n",
    "    units = da_masked.attrs.get(\"units\",\"\")\n",
    "    plt.xlabel(f\"{da_masked.name} ({units})\".strip())\n",
    "    plt.ylabel(\"Grid-cell count\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "def regional_stats(da_masked: xr.DataArray):\n",
    "    flat = da_masked.values[np.isfinite(da_masked.values)]\n",
    "    return pd.Series(flat).describe().rename({\"25%\":\"q25\",\"50%\":\"median\",\"75%\":\"q75\"})\n",
    "\n",
    "def to_linework_gdf(gdf, drop_points=True):\n",
    "    if gdf is None:\n",
    "        return None\n",
    "    try:\n",
    "        poly_mask = gdf.geometry.geom_type.isin(['Polygon','MultiPolygon'])\n",
    "        if poly_mask.any():\n",
    "            gdf = gdf.loc[poly_mask].set_geometry(gdf.loc[poly_mask].boundary)\n",
    "        if drop_points:\n",
    "            gdf = gdf.loc[~gdf.geometry.geom_type.isin(['Point','MultiPoint'])]\n",
    "        gdf = gdf.loc[gdf.geometry.geom_type.isin(['LineString','MultiLineString'])]\n",
    "        return gdf if len(gdf) else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def build_lowres_borders(shapefile_path: str):\n",
    "    if gpd is None:\n",
    "        return None\n",
    "    shp_full = _resolve_shp(shapefile_path)\n",
    "    if not shp_full or not os.path.exists(shp_full):\n",
    "        return None\n",
    "    try:\n",
    "        gdf = gpd.read_file(shp_full)\n",
    "    except Exception:\n",
    "        try:\n",
    "            gdf = gpd.read_file(shp_full, engine=\"pyogrio\")\n",
    "        except Exception:\n",
    "            return None\n",
    "    try:\n",
    "        if gdf.crs is not None and gdf.crs.to_epsg() != 4326:\n",
    "            gdf = gdf.to_crs(4326)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return to_linework_gdf(gdf, drop_points=True)\n",
    "\n",
    "def plot_map_cartopy(da_masked: xr.DataArray, title: str, xlim=None, ylim=None, cmap='viridis'):\n",
    "    \"\"\"Plot with Cartopy coastlines + national borders (low-res), always showing colorbar.\"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "    lons = da_masked['lon'].values\n",
    "    lats = da_masked['lat'].values\n",
    "    data = da_masked.values\n",
    "\n",
    "    proj = ccrs.PlateCarree()\n",
    "    fig, ax = plt.subplots(figsize=(9,4.5), subplot_kw=dict(projection=proj))\n",
    "    m = ax.pcolormesh(lons, lats, data, transform=proj, shading='auto', cmap=cmap)\n",
    "    cb = plt.colorbar(m, ax=ax)\n",
    "    units = da_masked.attrs.get('units','')\n",
    "    if units:\n",
    "        cb.set_label(units)\n",
    "\n",
    "    # Cartopy borders & coastlines \n",
    "    ax.coastlines(resolution='50m', linewidth=0.6, color='0.2')\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=0.6, edgecolor='k')\n",
    "\n",
    "    # Set extent if provided\n",
    "    if (xlim is not None) and (ylim is not None):\n",
    "        ax.set_extent([xlim[0], xlim[1], ylim[0], ylim[1]], crs=proj)\n",
    "\n",
    "    # ticks/labels\n",
    "    try:\n",
    "        ax.set_xticks(np.linspace(xlim[0], xlim[1], 5) if xlim else np.linspace(float(lons.min()), float(lons.max()), 5), crs=proj)\n",
    "        ax.set_yticks(np.linspace(ylim[0], ylim[1], 5) if ylim else np.linspace(float(lats.min()), float(lats.max()), 5), crs=proj)\n",
    "        ax.xaxis.set_major_formatter(LONGITUDE_FORMATTER)\n",
    "        ax.yaxis.set_major_formatter(LATITUDE_FORMATTER)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99437059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load data and compute multi-year mean ===================================\n",
    "os.makedirs(OUT_DIR, exist_ok=True) if SAVE_OUTPUTS else None\n",
    "nc_path = FILE_PATH\n",
    "da = load_dataarray(nc_path)\n",
    "da = ensure_lon_neg180_180(da)\n",
    "mean_da = da.mean(\"time\", skipna=True) if \"time\" in da.dims else da\n",
    "mean_da = mean_da.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Apply region mask and set axis limits ===================================\n",
    "region_label = \"global\"\n",
    "masked = mean_da\n",
    "xlim = None; ylim = None\n",
    "boundary_gdf = None\n",
    "\n",
    "if REGION_METHOD == \"country\":\n",
    "    poly = load_country_polygon(COUNTRY_NAME, SHAPEFILE_PATH)\n",
    "    if poly is not None:\n",
    "        masked = mask_da_by_polygon(mean_da, poly)\n",
    "        region_label = COUNTRY_NAME\n",
    "        try:\n",
    "            minx, miny, maxx, maxy = poly.bounds\n",
    "            pad_x = max(0.5, 0.05*(maxx-minx))\n",
    "            pad_y = max(0.5, 0.05*(maxy-miny))\n",
    "            xlim = (minx - pad_x, maxx + pad_x)\n",
    "            ylim = (miny - pad_y, maxy + pad_y)\n",
    "        except Exception:\n",
    "            xlim = None; ylim = None\n",
    "elif REGION_METHOD == \"bbox\":\n",
    "    masked = mask_da_by_bbox(mean_da, BBOX)\n",
    "    region_label = \"bbox\"\n",
    "    try:\n",
    "        minlon, minlat, maxlon, maxlat = BBOX\n",
    "        xlim = (minlon, maxlon); ylim = (minlat, maxlat)\n",
    "    except Exception:\n",
    "        xlim = None; ylim = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd788304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Map: multi-year mean with colorbar, units, and boundaries ===============\n",
    "title = f\"{masked.name} multi-year mean ({masked.attrs.get('units','')}) — {region_label}\"\n",
    "plot_map_cartopy(masked, title, xlim=xlim, ylim=ylim, cmap=CMAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb904f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Histogram of spatial distribution (multi-year mean) =====================\n",
    "plot_histogram(masked, f\"{masked.name} distribution — {region_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Spatial statistics table (multi-year mean) ==============================\n",
    "stats_df = regional_stats(masked)\n",
    "display(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea89181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Annual regional series and linear trend =================================\n",
    "if \"time\" in da.dims:\n",
    "    def area_weighted_mean_numpy(da2d):\n",
    "        lat = da2d[\"lat\"].values\n",
    "        arr = np.asarray(da2d.values, dtype=\"float64\")\n",
    "        w = np.cos(np.deg2rad(lat))\n",
    "        W = np.tile(w[:, None], (1, da2d.sizes[\"lon\"]))\n",
    "        valid = np.isfinite(arr) & np.isfinite(W)\n",
    "        if np.any(valid):\n",
    "            return float(np.nansum(arr[valid] * W[valid]) / np.nansum(W[valid]))\n",
    "        return np.nan\n",
    "\n",
    "    def apply_region_mask_2d(da2d):\n",
    "        if REGION_METHOD == \"country\":\n",
    "            poly = load_country_polygon(COUNTRY_NAME, SHAPEFILE_PATH)\n",
    "            return mask_da_by_polygon(da2d, poly) if poly is not None else da2d\n",
    "        elif REGION_METHOD == \"bbox\":\n",
    "            return mask_da_by_bbox(da2d, BBOX)\n",
    "        else:\n",
    "            return da2d\n",
    "\n",
    "    years = da[\"time\"].dt.year.values\n",
    "    year_labels = sorted(np.unique(years))\n",
    "    annual_vals = []\n",
    "    for y in year_labels:\n",
    "        da_y = da.sel(time=str(y))\n",
    "        da2d = da_y.mean(\"time\", skipna=True) if \"time\" in da_y.dims else da_y\n",
    "        da2d = ensure_lon_neg180_180(_standardize_latlon(da2d))\n",
    "        da2d = apply_region_mask_2d(da2d)\n",
    "        annual_vals.append(area_weighted_mean_numpy(da2d))\n",
    "\n",
    "    ts = pd.Series(annual_vals, index=year_labels, name=f\"{da.name} regional mean\")\n",
    "    display(ts.describe())\n",
    "\n",
    "    x = np.asarray(ts.index, dtype=float)\n",
    "    y = np.asarray(ts.values, dtype=float)\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[mask]; y = y[mask]\n",
    "    if x.size >= 3:\n",
    "        xbar = np.nanmean(x); ybar = np.nanmean(y)\n",
    "        Sxx = np.nansum((x - xbar)**2)\n",
    "        Sxy = np.nansum((x - xbar)*(y - ybar))\n",
    "        slope = float(Sxy / Sxx) if Sxx != 0 else np.nan\n",
    "        intercept = float(ybar - slope*xbar)\n",
    "        yhat = slope*x + intercept\n",
    "        SSE = np.nansum((y - yhat)**2)\n",
    "        SST = np.nansum((y - ybar)**2)\n",
    "        r2 = float(1.0 - SSE/SST) if SST != 0 else np.nan\n",
    "\n",
    "        print(f\"Slope per year: {slope}\")\n",
    "        print(f\"Slope per decade: {slope*10.0}\")\n",
    "        print(f\"R^2: {r2}\")\n",
    "\n",
    "        plt.figure(figsize=(9,3.2))\n",
    "        plt.plot(ts.index, ts.values, marker=\"o\")\n",
    "        plt.plot(ts.index, yhat, lw=2)\n",
    "        plt.xlabel(\"Year\"); plt.ylabel(f\"{da.name} ({da.attrs.get('units','')})\")\n",
    "        plt.title(f\"{da.name} regional mean — linear fit\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.hist(ts.values[np.isfinite(ts.values)], bins=15)\n",
    "        plt.xlabel(f\"{da.name} ({da.attrs.get('units','')})\")\n",
    "        plt.ylabel(\"Year count\")\n",
    "        plt.title(f\"{da.name} distribution across years\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "    else:\n",
    "        print(\"Not enough points for a trend (need >= 3).\")\n",
    "else:\n",
    "    print(\"No time dimension found; skipping annual series/trend.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce531ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Save map, histogram, and stats to files (if enabled) ====================\n",
    "if SAVE_OUTPUTS:\n",
    "    base = os.path.splitext(os.path.basename(FILE_PATH))[0]\n",
    "    map_png = os.path.join(OUT_DIR, f\"{base}_{region_label}_map.png\")\n",
    "    hist_png = os.path.join(OUT_DIR, f\"{base}_{region_label}_hist.png\")\n",
    "    csv_path = os.path.join(OUT_DIR, f\"{base}_{region_label}_stats.csv\")\n",
    "\n",
    "    # Map (Cartopy: coastlines + borders, colorbar with units)\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    proj = ccrs.PlateCarree()\n",
    "    fig, ax = plt.subplots(figsize=(9,4.5), subplot_kw=dict(projection=proj))\n",
    "    m = ax.pcolormesh(masked['lon'].values, masked['lat'].values, masked.values, transform=proj, shading='auto', cmap=CMAP)\n",
    "    cb = plt.colorbar(m, ax=ax)\n",
    "    units = masked.attrs.get('units','')\n",
    "    if units: cb.set_label(units)\n",
    "    ax.coastlines(resolution='110m', linewidth=0.6, color='0.2')\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale('110m'), linewidth=0.8, edgecolor='k')\n",
    "    if (xlim is not None) and (ylim is not None):\n",
    "        ax.set_extent([xlim[0], xlim[1], ylim[0], ylim[1]], crs=proj)\n",
    "    plt.tight_layout(); plt.savefig(map_png, dpi=150); plt.close()\n",
    "\n",
    "    # Histogram\n",
    "    flat = masked.values[np.isfinite(masked.values)]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(flat, bins=40)\n",
    "    plt.xlabel(f\"{masked.name} ({units})\".strip()); plt.ylabel(\"Grid-cell count\")\n",
    "    plt.title(f\"{masked.name} distribution — {region_label}\")\n",
    "    plt.tight_layout(); plt.savefig(hist_png, dpi=150); plt.close()\n",
    "\n",
    "    stats_df.to_csv(csv_path, index=True)\n",
    "    print(\"Saved:\"); print(map_png); print(hist_png); print(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81e5f2-91a8-46bd-aa56-27197143b404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
