{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486a9ad4",
   "metadata": {},
   "source": [
    "# ETCCDI **pr** Indices Driver\n",
    "\n",
    "Run cells **top-to-bottom**. Steps:\n",
    "1. Parameters\n",
    "2. Helpers\n",
    "3. Locate & load data\n",
    "4. Compute indices\n",
    "5. Save to NetCDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 1: Parameters ===\n",
    "ROOT = \"/home/jovyan/shared/NEX-GDDP-CMIP6/\"\n",
    "MODEL = \"GISS-E2-1-G\"\n",
    "SCENARIO = \"historical\"   # \"historical\",\"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\"\n",
    "MEMBER = \"r1i1p1f2\"\n",
    "START_YEAR = 1985\n",
    "END_YEAR   = 2014\n",
    "SEASON = \"annual\"         # \"annual\",\"MAM\",\"JJA\",\"SON\",\"DJF\"\n",
    "OUTDIR = \"./etccdi_out\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f762a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 2: Helpers ===\n",
    "from pathlib import Path\n",
    "import re, warnings\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kwargs): return x\n",
    "\n",
    "SEASONS = (\"annual\",\"MAM\",\"JJA\",\"SON\",\"DJF\")\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, model, scenario, member, start_year, end_year, season):\n",
    "        self.model = model\n",
    "        self.scenario = scenario\n",
    "        self.member = member\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        self.season = season\n",
    "\n",
    "def _validate_args(args, available_scenarios=(\"historical\",\"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\")):\n",
    "    if args.scenario == \"historical\":\n",
    "        if args.start_year < 1950 or args.end_year > 2014:\n",
    "            raise ValueError(\"Historical is only valid for 1950–2014.\")\n",
    "    else:\n",
    "        if args.start_year < 2015 or args.end_year > 2100:\n",
    "            raise ValueError(\"Future SSP scenarios are only valid for 2015–2100.\")\n",
    "    if args.season not in SEASONS:\n",
    "        raise ValueError(f\"season must be one of {SEASONS}\")\n",
    "    if args.end_year < args.start_year:\n",
    "        raise ValueError(\"end_year must be >= start_year\")\n",
    "\n",
    "def _suppress_nan_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", message=\"All-NaN slice encountered\", category=RuntimeWarning)\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Mean of empty slice\", category=RuntimeWarning)\n",
    "\n",
    "def _year_from_name(name: str):\n",
    "    m = re.search(r'_(\\d{4})_v', name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def _select_years(files, start_year, end_year):\n",
    "    out = []\n",
    "    for p in files:\n",
    "        y = _year_from_name(Path(p).name)\n",
    "        if y is not None and start_year <= y <= end_year:\n",
    "            out.append(Path(p))\n",
    "    return sorted(out)\n",
    "\n",
    "def _scan_standard(root: str, model: str, scenario: str, member: str, varname: str):\n",
    "    return sorted((Path(root) / model / scenario / member / varname).glob(\"*.nc\"))\n",
    "\n",
    "def _scan_recursive(root: str, model: str, scenario: str, member: str, varname: str):\n",
    "    out = []\n",
    "    root = Path(root)\n",
    "    for p in root.rglob(\"*.nc\"):\n",
    "        n = p.name\n",
    "        if n.startswith(f\"{varname}_day_\") and f\"_{model}_\" in n and f\"_{scenario}_\" in n and f\"_{member}_\" in n:\n",
    "            out.append(p)\n",
    "    return sorted(out)\n",
    "\n",
    "def _build_file_list_flexible(root: str, model: str, scenario: str, member: str, varname: str,\n",
    "                              start_year: int, end_year: int):\n",
    "    std_dir = Path(root) / model / scenario / member / varname\n",
    "    if std_dir.exists():\n",
    "        std = _select_years(sorted(std_dir.glob(\"*.nc\")), start_year, end_year)\n",
    "        if std:\n",
    "            return std, {\"method\": \"standard\", \"looked_in\": str(std_dir)}\n",
    "    rec_root = Path(root) / model / scenario\n",
    "    if rec_root.exists():\n",
    "        rec = _select_years(_scan_recursive(rec_root, model, scenario, member, varname), start_year, end_year)\n",
    "        if rec:\n",
    "            return rec, {\"method\": \"recursive\", \"looked_in\": str(rec_root)}\n",
    "    rec2 = _select_years(_scan_recursive(root, model, scenario, member, varname), start_year, end_year)\n",
    "    if rec2:\n",
    "        return rec2, {\"method\": \"recursive\", \"looked_in\": str(root)}\n",
    "    raise FileNotFoundError(f\"No files found for {model}/{scenario}/{member}/{varname} {start_year}-{end_year}\")\n",
    "\n",
    "def _open_dataset(files, varname: str):\n",
    "    ds = xr.open_mfdataset([str(f) for f in files], combine=\"by_coords\", decode_times=True)\n",
    "    if varname not in ds:\n",
    "        cand = [k for k in ds.data_vars if k.lower()==varname.lower()]\n",
    "        if not cand:\n",
    "            raise KeyError(f\"Variable '{varname}' not in dataset. Available: {list(ds.data_vars)}\")\n",
    "        varname = cand[0]\n",
    "    da = ds[varname].sortby(\"time\")\n",
    "    return da\n",
    "\n",
    "def _subset_season(da: xr.DataArray, season: str) -> xr.DataArray:\n",
    "    if season == \"annual\":\n",
    "        return da\n",
    "    month_sets = {\"MAM\":[3,4,5],\"JJA\":[6,7,8],\"SON\":[9,10,11],\"DJF\":[12,1,2]}\n",
    "    months = month_sets[season]\n",
    "    sub = da.sel(time=da[\"time\"].dt.month.isin(months))\n",
    "    if season == \"DJF\":\n",
    "        year = xr.where(sub[\"time\"].dt.month==12, sub[\"time\"].dt.year+1, sub[\"time\"].dt.year)\n",
    "        sub = sub.assign_coords(season_year=(\"time\", year.values))\n",
    "    return sub\n",
    "\n",
    "def _maybe_mm_per_day(pr: xr.DataArray) -> xr.DataArray:\n",
    "    units = str(pr.attrs.get(\"units\", \"\")).lower()\n",
    "    pr2 = pr\n",
    "    if \"kg m-2 s-1\" in units or units==\"kg m-2 s-1\" or units==\"kg/m^2/s\" or \"kg m**-2 s**-1\" in units:\n",
    "        pr2 = pr * 86400.0\n",
    "        pr2.attrs[\"units\"] = \"mm day-1\"\n",
    "    elif \"m day-1\" in units or \"m/day\" in units:\n",
    "        pr2 = pr * 1000.0\n",
    "        pr2.attrs[\"units\"] = \"mm day-1\"\n",
    "    return pr2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6f20fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotfix not needed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Step 2.5 (optional): Hotfix for assign_coords(doy=...) error in ETCCDI_pr_indices ===\n",
    "# Run this only if Step 4 errors with \"Using a DataArray object to construct a variable is ambiguous\"\n",
    "try:\n",
    "    import importlib, re, pathlib, ETCCDI_pr_indices as _et\n",
    "    _p = pathlib.Path(_et.__file__)\n",
    "    _s = _p.read_text()\n",
    "    _new = re.sub(r'assign_coords\\(\\s*doy=\\(\\s*\"time\"\\s*,\\s*doy\\s*\\)\\s*\\)',\n",
    "                  'assign_coords(doy=(\\\"time\\\", doy.values))', _s)\n",
    "    if _new != _s:\n",
    "        _p.write_text(_new); importlib.reload(_et)\n",
    "        print(\"Patched ETCCDI_pr_indices for assign_coords(doy=...)\")\n",
    "    else:\n",
    "        print(\"Hotfix not needed.\")\n",
    "except Exception as _e:\n",
    "    print(\"Hotfix check skipped:\", _e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8843e18d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No files found for GISS-E2-1-G/historical/r1i1p1f2/pr 1985-2014",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m args \u001b[38;5;241m=\u001b[39m Args(MODEL, SCENARIO, MEMBER, START_YEAR, END_YEAR, SEASON)\n\u001b[1;32m      3\u001b[0m _validate_args(args)\n\u001b[0;32m----> 5\u001b[0m files, info \u001b[38;5;241m=\u001b[39m \u001b[43m_build_file_list_flexible\u001b[49m\u001b[43m(\u001b[49m\u001b[43mROOT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCENARIO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMEMBER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTART_YEAR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_YEAR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files via \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlooked_in\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample:\u001b[39m\u001b[38;5;124m\"\u001b[39m, files[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mif\u001b[39;00m files \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 78\u001b[0m, in \u001b[0;36m_build_file_list_flexible\u001b[0;34m(root, model, scenario, member, varname, start_year, end_year)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rec2:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rec2, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursive\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlooked_in\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(root)}\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscenario\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmember\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvarname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No files found for GISS-E2-1-G/historical/r1i1p1f2/pr 1985-2014"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Step 3: Locate & load (pr) ===\n",
    "args = Args(MODEL, SCENARIO, MEMBER, START_YEAR, END_YEAR, SEASON)\n",
    "_validate_args(args)\n",
    "\n",
    "files, info = _build_file_list_flexible(ROOT, MODEL, SCENARIO, MEMBER, \"pr\", START_YEAR, END_YEAR)\n",
    "print(f\"Found {len(files)} files via {info['method']} in {info['looked_in']}\")\n",
    "print(\"Example:\", files[0].name if files else \"None\")\n",
    "\n",
    "da = _open_dataset(files, \"pr\")\n",
    "da = _subset_season(da, SEASON)\n",
    "print(\"Loaded pr shape:\", tuple(da.shape), \"time span:\", str(da['time'].values[0])[:10], \"->\", str(da['time'].values[-1])[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 4: Compute ETCCDI pr indices ===\n",
    "_suppress_nan_warnings()\n",
    "import ETCCDI_pr_indices as et\n",
    "import xarray as xr\n",
    "\n",
    "# Auto-load if Step 3 wasn't run\n",
    "try:\n",
    "    da\n",
    "except NameError:\n",
    "    args = Args(MODEL, SCENARIO, MEMBER, START_YEAR, END_YEAR, SEASON)\n",
    "    _validate_args(args)\n",
    "    files, info = _build_file_list_flexible(ROOT, MODEL, SCENARIO, MEMBER, \"pr\", START_YEAR, END_YEAR)\n",
    "    print(f\"Auto-loaded {len(files)} files via {info['method']} in {info['looked_in']}\")\n",
    "    da = _open_dataset(files, \"pr\"); da = _subset_season(da, SEASON)\n",
    "\n",
    "pr = _maybe_mm_per_day(da)\n",
    "'''\n",
    "tasks = [\n",
    "    (\"Rx1day\",  lambda: et.Rx1day(pr, period=\"annual\")),\n",
    "    (\"Rx5day\",  lambda: et.Rx5day(pr, period=\"annual\")),\n",
    "    (\"SDII\",    lambda: et.SDII(pr, period=\"annual\")),\n",
    "    (\"R10mm\",   lambda: et.R10mm(pr, period=\"annual\")),\n",
    "    (\"R20mm\",   lambda: et.R20mm(pr, period=\"annual\")),\n",
    "    (\"PRCPTOT\", lambda: et.PRCPTOT(pr, period=\"annual\")),\n",
    "    (\"R95pTOT\", lambda: et.R95pTOT(pr, period=\"annual\")),\n",
    "    (\"R99pTOT\", lambda: et.R99pTOT(pr, period=\"annual\")),\n",
    "    (\"CDD\",     lambda: et.CDD(pr, period=\"annual\")),\n",
    "    (\"CWD\",     lambda: et.CWD(pr, period=\"annual\")),\n",
    "]\n",
    "'''\n",
    "tasks = [\n",
    "    (\"Rx1day\",  lambda: et.Rx1day(pr, period=\"annual\")),\n",
    "    (\"Rx5day\",  lambda: et.Rx5day(pr, period=\"annual\")),\n",
    "    (\"SDII\",    lambda: et.SDII(pr, period=\"annual\")),\n",
    "    (\"R10mm\",   lambda: et.R10mm(pr, period=\"annual\")),\n",
    "    (\"R20mm\",   lambda: et.R20mm(pr, period=\"annual\")),\n",
    "    (\"PRCPTOT\", lambda: et.PRCPTOT(pr, period=\"annual\")),\n",
    "    (\"CDD\",     lambda: et.CDD(pr, period=\"annual\")),\n",
    "    (\"CWD\",     lambda: et.CWD(pr, period=\"annual\"))\n",
    "]\n",
    "\n",
    "out = {}\n",
    "for name, fn in tqdm(tasks, desc=\"ETCCDI pr\", unit=\"idx\"):\n",
    "    print(f\"[pr] computing {name} ...\")\n",
    "    out[name] = fn()\n",
    "\n",
    "# Align time axes\n",
    "aligned = xr.align(*out.values(), join='outer')\n",
    "out = {k: v for (k,_), v in zip(out.items(), aligned)}\n",
    "ds = xr.Dataset(out)\n",
    "# Mask PRCPTOT/R10mm/R20mm at locations with all-NaN input over time\n",
    "spatial_dims = [d for d in da.dims if d != 'time']\n",
    "obs_mask = da.where(np.isfinite(da)).count('time') > 0\n",
    "for key in ['PRCPTOT','R10mm','R20mm']:\n",
    "    if key in ds.data_vars:\n",
    "        ds[key] = ds[key].where(obs_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69cf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 5: Save to NetCDF (simple) ===\n",
    "from pathlib import Path as _P\n",
    "_P(OUTDIR).mkdir(parents=True, exist_ok=True)\n",
    "outfile = _P(OUTDIR) / f\"ETCCDI_pr_{MODEL}_{SCENARIO}_{SEASON}_{START_YEAR}-{END_YEAR}.nc\"\n",
    "\n",
    "for v in ds.data_vars:\n",
    "    ds[v].attrs.setdefault(\"long_name\", v)\n",
    "\n",
    "DISCLAIMER_TEXT = (\"ALL INDICES PRODUCED BY THESE SCRIPTS/MODULES ARE EXPERIMENTAL. \"\n",
    "                   \"USERS MUST REVIEW THE CODE AND VALIDATE RESULTS AGAINST KNOWN REFERENCES \"\n",
    "                   \"BEFORE ANY OPERATIONAL OR DECISION SUPPORT USE. THERE MAY BE ERRORS.\")\n",
    "ds.attrs.update({\n",
    "    \"model\": MODEL,\n",
    "    \"scenario\": SCENARIO,\n",
    "    \"member\": MEMBER,\n",
    "    \"period\": f\"{START_YEAR}-{END_YEAR}\",\n",
    "    \"season\": SEASON,\n",
    "    \"disclaimer\": DISCLAIMER_TEXT\n",
    "})\n",
    "\n",
    "import warnings, gc, numpy as np\n",
    "import netCDF4 as nc\n",
    "\n",
    "# Prepare coordinate references\n",
    "_time = ds.coords[\"time\"]\n",
    "_lat = ds.coords[\"lat\"]\n",
    "_lon = ds.coords[\"lon\"]\n",
    "\n",
    "def _encode_time_days(time_index):\n",
    "    \"\"\"Return numeric days since epoch plus units/calendar for CF-ish encoding.\"\"\"\n",
    "    try:\n",
    "        t64 = np.array(time_index.values).astype(\"datetime64[ns]\")\n",
    "        base = np.datetime64(\"1970-01-01T00:00:00\")\n",
    "        days = (t64 - base) / np.timedelta64(1, \"D\")\n",
    "        return np.asarray(days, dtype=\"float64\"), \"days since 1970-01-01 00:00:00\", \"standard\"\n",
    "    except Exception:\n",
    "        # Fallback: index units\n",
    "        return np.arange(time_index.size, dtype=\"float64\"), \"index\", \"none\"\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "_base = outfile  # we'll append _{var}.nc\n",
    "\n",
    "for _v in ds.data_vars:\n",
    "    _da = ds[_v].astype(\"float32\")\n",
    "    # enforce canonical ordering for safety\n",
    "    try:\n",
    "        _da = _da.transpose(\"time\", \"lat\", \"lon\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    _dims = tuple(_da.dims)\n",
    "    _shape = tuple(_da.shape)\n",
    "\n",
    "    _out_path = _base.with_name(_base.stem + f\"_{_v}.nc\")\n",
    "    tvals, tunits, tcal = _encode_time_days(_time)\n",
    "\n",
    "    # Write with netCDF4 (no compression, very fast)\n",
    "    with nc.Dataset(str(_out_path), \"w\", format=\"NETCDF4\") as _nc:\n",
    "        # Dimensions\n",
    "        _nc.createDimension(\"time\", size=_da.sizes.get(\"time\", len(tvals)))\n",
    "        _nc.createDimension(\"lat\", size=_da.sizes.get(\"lat\", len(_lat)))\n",
    "        _nc.createDimension(\"lon\", size=_da.sizes.get(\"lon\", len(_lon)))\n",
    "\n",
    "        # Coordinate variables\n",
    "        tv = _nc.createVariable(\"time\", \"f8\", (\"time\",))\n",
    "        yv = _nc.createVariable(\"lat\", \"f4\", (\"lat\",))\n",
    "        xv = _nc.createVariable(\"lon\", \"f4\", (\"lon\",))\n",
    "        tv[:] = tvals\n",
    "        yv[:] = np.asarray(_lat.values, dtype=\"float32\")\n",
    "        xv[:] = np.asarray(_lon.values, dtype=\"float32\")\n",
    "        tv.units = tunits; tv.calendar = tcal\n",
    "        yv.units = getattr(getattr(_lat, \"attrs\", {}), \"get\", lambda k, d=None: d)(\"units\", \"degrees_north\")\n",
    "        xv.units = getattr(getattr(_lon, \"attrs\", {}), \"get\", lambda k, d=None: d)(\"units\", \"degrees_east\")\n",
    "\n",
    "        # Data variable\n",
    "        var = _nc.createVariable(_v, \"f4\", (\"time\", \"lat\", \"lon\"), zlib=False)\n",
    "        var[:] = np.asarray(_da.values, dtype=\"float32\")\n",
    "        var.long_name = ds[_v].attrs.get(\"long_name\", _v)\n",
    "        if \"units\" in ds[_v].attrs:\n",
    "            var.units = ds[_v].attrs[\"units\"]\n",
    "\n",
    "        # Global attributes\n",
    "        for _k, _val in ds.attrs.items():\n",
    "            try:\n",
    "                setattr(_nc, _k, str(_val))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    print(f\"Wrote {_out_path.name} | dims={_dims} shape={_shape}\")\n",
    "    del _da\n",
    "    gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
